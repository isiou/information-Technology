# Web 应用的反向代理与负载平衡

Web 应用的反向代理是能使其接收来自客户端（如日常使用的浏览器）的请求，并将这些请求转发给内部网络中的一个或多个服务器，之后再将服务器的响应返回给客户端（或浏览器）。

在这个过程中，客户端并不直接与实际处理请求的服务器通信，而是与反向代理服务器进行交互，对于客户端来说，反向代理就和真实服务器一样。

反向代理具有实现负载均衡、保护安全和隐藏真实服务器（如 cloudflare 代理）等作用。

## 反向代理

常见的反向代理软件有 Nginx、Apache 等，本文以 Nginx 做演示，简单的静态配置参见 [部署 SSL 证书 <前置：配置 Nginx 服务器>](./05-部署%20SSL%20证书.md) 章节。

反向代理明显特征是需要使用 `proxy_pass` 指令将请求转发到后端服务器。

> 安装配置等不在此赘述，详情请查看上一节。
>
> 配置 Web 服务器前推荐将自己的 `C:\Windows\System32\drivers\etc\hosts` 文件中添加相应的自定义域名和记录：
>
> ![202407170818474](https://oss.isiou.cn//images/202407170818474.png)

### 反向代理概念

通常情况下，将后端服务暴露在公网上是十分危险的，所以需要一种工具将后端隐藏。

假设现在有一个运行在 `http://server.com:8080` 上的服务，若想不暴露其位置，则可以配置反向代理如 `example.com` 将其接受到的请求转发到 `http://server.com:8080` 上。

另外，反向代理不仅仅只是隐藏后端，还包括当作中间件、进行 SSL 加密等。

### 配置

```conf
# 服务块，定义一个服务
server {
    # 监听端口，默认 http 是 80 端口
    listen 80;
    # 指定服务器域名
    server_name e.com;

    # 监听位于 e.com 上的所有请求 /
    location / {
        # 反向代理的核心配置，将接收到的请求转发到位于 http://server.com:8080 的后端服务器上
        proxy_pass http://server.com:8080;
        # 同时转发原请求的请求头
        proxy_set_header Host $host;
    }
}
```

在以上配置中，Nginx 监听 `e.com` 的 80 端口，并匹配 `e.com` 上的所有请求（`/`）将其转发到后端服务器 `http://server.com:8080` 上。

`proxy_set_header Host $host` 则是将 `e.com` 上请求的请求头（包含原请求的信息，即请求的目标地址、客户端版本等）同时转发给后端服务器，确保后端服务器能够正确识别请求的域名。

> 关于请求、请求头等详细概念，请自行查找相关资料。

同时，关于 `location` 块内还有很多配置选项，也可以设置只响应对应的请求如：

```conf
# 定义监听 /images/ 请求
location /images/ {
    # 指定了静态图片文件的根目录为 /var/www/images，当客户端请求 /images/ 路径下的任何文件时，Nginx 会从这个目录中查找对应的文件并返回给客户端
    root /var/www/images;
    # 指定缓存过期时间为 30 天，超出期限后会重新读取目录下文件返回客户端
    expires 30d;
}

# 定义监听 /api/ 请求
location /api/ {
    # 将其转发至 http://server.com:8888
    proxy_pass http://server.com:8888;
    # 同时转发请求头
    proxy_set_header Host $host;
}
```

## 负载平衡

负载均衡将流量分配到不同的后端服务器，包括主服务器和附属服务器，以平衡压力。反向代理服务（如 Nginx）可以作为负载均衡器的组成部分，负责接收来自客户端的请求，根据负载均衡器的配置转发到不同的后端服务器，并处理请求和返回响应。

> 本文以 10 台主机做演示，其中 4 台作负载均衡，剩余 6 台为正常服务器。

如图所示：

![202407181402456](https://oss.isiou.cn//images/202407181402456.png)

其中，Debian-Client 01-06 为正常服务器，07-10 为负载均衡服务器，IP 为 192.168.110.121-192.168.110.130，每台服务器上均安装 Nginx 并启动。

> 推荐使用 [Ansible](./07-部署%20Ansible%20自动化运维.md) 进行批量安装 Nginx 并启动。

修改 01-06 服务器中 `/var/www/html/index.nginx-debian.html` 内容，参考如下：

> 此步是为了分辨负载平衡器将请求转移到哪台服务器上，内容可以自定义，分清即可。

![202407181408084](https://oss.isiou.cn//images/202407181408084.png)

修改完 01-06 服务器后重启 Nginx 服务。

```shell
systemctl restart nginx.service
```

修改 07-10 服务器中 `/etc/nginx/nginx.conf` 文件，在其中 `http` 块添加以下行：

```conf
http {
    # 定义了一个名为 backend 的 upstream 集群，其由正常服务器组成
    upstream backend {
        server 192.168.110.121;
        server 192.168.110.122;
        server 192.168.110.123;
        server 192.168.110.124;
        server 192.168.110.125;
        server 192.168.110.126;
    }

    server {
        listen 80;

        # 匹配所有请求的 location 块
        location / {
            #  将所有请求转发到 backend upstream 集群
            proxy_pass http://backend;
            # 同时转发请求头
            proxy_set_header Host $host;
            # 将客户端的真实 IP 地址传递给后端服务器
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            # 将请求协议（如 http 或 https）传递给后端服务器
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
}
```

如图：

![202407181414991](https://oss.isiou.cn//images/202407181414991.png)

> 验证：浏览器访问 192.168.110.127-192.168.110.130 后会转到之前设置的页面中，如图：
>
> ![202407181431877](https://oss.isiou.cn//images/202407181431877.png)
>
> ![202407181431354](https://oss.isiou.cn//images/202407181431354.png)

**解析**：此处配置定义了一个反向代理的网关，假设目前是在 192.168.110.127 服务器的 Nginx 上配置的服务。那么当客户端向 192.168.110.127:80 （一般为浏览器）发起请求，本服务器会监听 80 端口并识别到 `/` 请求。之后，会将客户端发起的请求转移到 upstream 定义的后端服务器集群，由后端服务器集群内的任何一个对客户端发起的请求做回应（如 192.168.110.123），并且在本服务器向后端服务器集群转发时，会将源请求的请求头、客户端 IP 地址、协议等一并转发给后端服务器集群中的一台。

至此，一个简单的反向代理和负载平衡已经搭建完成，若要配置更多的代理条件还需更多配置。

## 负载平衡的四种实现方式

### 轮询

轮询是指 Nginx 服务器会以后端集群顺序，把每个请求按顺序轮流分配到不同的后端服务器。

上述配置即为简单轮询，此处不再讲述。

### 权重

权重平衡可以根据后端服务器的性能设置权重，权重越高的服务器分配到的请求越多。

配置方法只需更改上述 `/etc/nginx/nginx.conf` 文件，对其 http 块内 upstream 做以下修改：

```conf
http {
    upstream backend {
        # 设置权重
        server 192.168.110.121 weight=1;
        server 192.168.110.122 weight=1;
        server 192.168.110.123 weight=1;
        server 192.168.110.124 weight=2;
        server 192.168.110.125 weight=2;
        server 192.168.110.126 weight=3;
    }
    server {
        listen 80;
        location / {
            proxy_pass http://backend;
        }
    }
}
```

### 最少连接

最少连接策略会将请求分配到当前连接数最少的后端服务器，适用于请求处理时间差异较大的场景。

```conf
http {
    upstream backend {
        # 启用最少连接策略
        least_conn;
        server 192.168.110.121;
        server 192.168.110.122;
        server 192.168.110.123;
        server 192.168.110.124;
        server 192.168.110.125;
        server 192.168.110.126;
    }
    server {
        listen 80;
        location / {
            proxy_pass http://backend;
        }
    }
}
```

### IP_hash

配置 IP_hash 后 Nginx 会根据客户端的 IP 地址分配请求，保证同一个 IP 地址的请求始终分配到同一台后端服务器。

```conf
http {
    upstream backend {
        # 启用 IP_hash
        ip_hash;
        server 192.168.110.121;
        server 192.168.110.122;
        server 192.168.110.123;
        server 192.168.110.124;
        server 192.168.110.125;
        server 192.168.110.126;
    }
    server {
        listen 80;
        location / {
            proxy_pass http://backend;
        }
    }
}
```

## Nginx 充当网关

现在有以下需求：在十台虚拟机上分别部署 Nginx 服务并启动，并且要求其中三台作为负载平衡器，将流量分拨到六台正常的 Web 服务器上。另外一台作为网关，用于域名 DNS 解析，承担所有入口流量并将其分拨给三台负载平衡器，再由负载平衡器分拨到 Web 服务器上并响应。除入口机外，其他服务器流量只允许在内网内流通。

IP 池：192.168.110.121-192.168.110.130，如图所示：

![202407191521582](https://oss.isiou.cn/images/202407191521582.png)

01-06 号机做正常 Web 服务器，07-09 号机做 负载均衡器，10 号机做入口机。

### 思路整理

由需求可知，此目的主要是为保证安全，使内网服务器不暴露在公网上只允许在内网流通，故需要设置 01-09 号机的防火墙使其只开放 192.168.110.0 网段（机器所处内网）。

由于 10 号机作为入口机，则需要设置 10 号机接受所有流量。

> 重点：设置防火墙并设置服务器流量只在内网流通。

### 配置过程

1. 对于 01-06 号机，作为 Web 应用服务器只需设置对应的 Web 服务和防火墙即可。参考配置：

   - 配置 `/etc/nginx/nginx.conf` 文件：

     > 这里以 Nginx 默认站点为 Web 应用举例，即为默认配置。

     ```conf
     http {
        sendfile on;
        tcp_nopush on;
        types_hash_max_size 2048;
        include /etc/nginx/mime.types;
        default_type application/octet-stream;
        ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3;
        ssl_prefer_server_ciphers on;
        access_log /var/log/nginx/access.log;
        gzip on;
        include /etc/nginx/conf.d/*.conf;
        include /etc/nginx/sites-enabled/*;
     }
     ```

   - 配置防火墙：

     这里使用 ufw 防火墙为例。

     ```shell
     # 安装 ufw
     apt install ufw -y
     # 启动、设置自启动并查看 ufw 状态
     systemctl restart ufw.service && systemctl enable ufw && systemctl status ufw.service
     # 查看 ufw 规则
     ufw status
     # 放入常用规则，若要为了安全可以只留 22
     ufw allow 80/tcp
     ufw allow 443/tcp
     ufw allow 22/tcp
     ufw allow 21/tcp
     # 允许指定 IP 的连接
     sudo ufw allow from 192.168.110.127 to any
     sudo ufw allow from 192.168.110.128 to any
     sudo ufw allow from 192.168.110.129 to any
     ```

     使用 `ufw status` 查看规则，如图所示：

     ![202407191610420](https://oss.isiou.cn/images/202407191610420.png)

     > 若想更快、更方便的配置所有主机，推荐使用 Ansible 进行配置。

2. 对于 07-09 号机，作为负载均衡器则需配置器负载规则，参考如下：

   - 配置 `/etc/nginx/nginx.conf` 文件：

     ```conf
     http {
        upstream backend {
            # 根据权重分配
            server 192.168.110.121 weight=1;
            server 192.168.110.122 weight=2;
            server 192.168.110.123 weight=2;
            server 192.168.110.124 weight=3;
            server 192.168.110.125 weight=3;
            server 192.168.110.126 weight=5;
        }

        server {
            listen 80;
            location / {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            }
        }
     }
     ```

   - 配置防火墙：

     负载均衡器遵守和上述 Web 应用服务器一样的规则，参考上述配置即可。

3. 对于 10 号机，负责接受所有传入连接并将其分配给负载均衡器，参考配置如下：

   - 配置 `/etc/nginx/nginx.conf` 文件：

     ```conf
     http {
        upstream backend {
            # 权重负载
            server 192.168.110.127 weight=1;
            server 192.168.110.128 weight=2;
            server 192.168.110.129 weight=3;
        }

        server {
            listen 80;

            location / {
                # 将接受到的请求转发到后端服务器集群，此处为负载均衡器集群
                proxy_pass http://backend;
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
            }
        }
     }
     ```

   - 配置防火墙：

     此防火墙要求接受所有传入连接，并将请求分拨到负载平衡器集群，负载平衡器集群再进行分配到 Web 服务器上。

     ```shell
     # 放入常用规则
     ufw allow 80/tcp
     ufw allow 443/tcp
     ufw allow 22/tcp
     ufw allow 21/tcp
     ```
